\section{Implementation Details}
\subsection{Object Proposals}
We use MCG object proposals in~\cite{arbelaez2014multiscale} as object candidates. Since the object proposals mainly covers the objects,  we also generate a small amount (20$\sim$30 per image) of segments using stable segmentation algorithm in~\cite{chen2011piecing} to cover the whole scene including contextual classes. To reduce the computation overhead, our context voting step uses only the stable segments. The stable segmentation gives a coarse level of object/context division and reduces the computation complexity of context voting compared to the large number of finer object proposals, while still maintains a semantically reasonable context inference. 

\subsection{Datasets}
We conduct our training and experiments on the Pascal VOC dataset.~\cite{Everingham10} which is a \textit{de facto} benchmark for object detection for years. Since the original dataset does not provide annotation of segmentation and contextual classes, we train our policy using the Pascal Context dataset~\cite{mottaghi2014role} which fully annotates the every pixels of the Pascal VOC 2010 train and validation sets, with additional contextual classes, which is perfectly good for our task. We use the 33 context classes and train our policy on the Pascal Context training set, and test our algorithm and baselines on the validation set. We also test our policy on the MSRC dataset~\cite{shotton2006textonboost} to show our algorithm can generalize to different data. 

\section{Experiments}

\subsection{Reduction of Number of Object Proposals}

Figure~\ref{fig:mapVSnumprop} shows that our 20 questions detection algorithm can effectively reduce a large amount of object proposals ($30\% \sim 40\%$) while maintaining similar mAP performance compared to exhaustive detection on all object proposals.  

\subsection{Comparison with other context driven methods}

% ferrarri 2012
~\cite{bogdan2012context} 25000 to 100 
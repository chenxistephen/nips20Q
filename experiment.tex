\section{Implementation Details}
\subsection{Object Proposals}
We use MCG object proposals in~\cite{arbelaez2014multiscale} as object candidates. Since the object proposals mainly covers the objects,  we also generate a small number (20$\sim$30 per image) of segments using the stable segmentation algorithm from~\cite{chen2011piecing} to cover the whole scene including contextual classes. To reduce the computational overhead, our context voting step uses only the stable segments. The stable segmentation gives a coarse level of object/context division and reduces the computational complexity of context voting compared to the large number of finer object proposals, while still maintaining a semantically informative contextual inference. 

\subsection{Datasets}
We conduct our training and experiments on the Pascal VOC dataset.~\cite{Everingham10} which is a \textit{de facto} benchmark for object detection. Since the original dataset does not provide annotation of segmentation and contextual classes, we train our policy using the Pascal Context dataset~\cite{mottaghi2014role} which fully annotates every pixel of the Pascal VOC 2010 train and validation sets, with additional contextual classes such as sky, grass, ground, building etc., which is adequate for our purposes. We use the 33 context classes from~\cite{mottaghi2014role} and train our policy on the Pascal Context training set, and test our algorithm and baselines on the validation set. We also test our policy on the MSRC dataset~\cite{shotton2006textonboost} to show our algorithm can generalize to different data. 

\subsection{Feature Representation}
To classify object proposals, we extract region features and classify them using the deep neural network model in~\cite{BharathECCV2014} fine-tuned on Pascal VOC 2012. For the policy action classifiers, we also use the same model to extract features for states represented by the masks of search area $X^t$ and observed area $O^t$ in state $s_t$, then concatenate the features as inputs to the policy. For context classifiers we use a subset of the appearance features for superpixels from~\cite{tighe2010superparsing} and learn one-vs-all SVM models for classification.

\section{Experiments}

\subsection{Reduction of Number of Object Proposals}

Figure~\ref{fig:mapVSnumprop} shows that our 20 questions detection algorithm can effectively reduce a large amount of object proposals ($30\% \sim 40\%$) while maintaining similar mAP performance compared to exhaustive detection on all object proposals.  

\subsection{Comparison with other context based methods}

\subsection{Comparison with random search methods}


% ferrarri 2012
% ~\cite{bogdan2012context} 25000 to 100 
\section{Related Work}
\label{sec:relatedwork}

{\bf{Sequential Testing}}. 
The ``20 question'' approach to pattern recognition dates back to Blanchard and Geman~\cite{blanchard2005hierarchical}, motivated by the scene interpretation problem with a large number of possible explanations. They formally studied coarse-to-fine search in the theoretical framework of sequential hypothesis testing, and proposed optimal strategies considering both the cost and effectiveness of each test. Although they did not consider contextual information, their work provides a theoretical foundation for the design of sequential algorithms. ``20 questions" approaches recently have been used to generating questions for users in applications such as image binary segmentation~\cite{rupprecht2015image} and ``visual Turing test''~\cite{geman2015visual}. But such methods involve human in the loop during test time, which is expensive and hard to scale up.  Recently there is a trend of investigating the sequential process of visual attention~\cite{paletta2005q, ranzato2014learning, larochelle2010learning} to model the spatial transition of fixation in images. However, such methods focus on low level salience and are tested in simple scenario such as MNIST dataset. 

There are several works~\cite{gao2011active} on objects classification by running classifiers sequentially in an active order.~\cite{branson2010visual} proposed an information gain based approach to iteratively pose questions for users and incorporate human responses and computer vision detector results for fine-grained classification.
~\cite{sergey2012timely} formulated object classification as a Markov decision process to select classifiers under certain time constraint. However, these approaches only focus on classifying objects. They have not addressed the challenging problem of simultaneous segmentation and localization of objects in a multi-class scene as we do in this paper, and did not exploit inter-object spatial context.



{\bf Object Detection}. 
A common approach to object detection is based on applying gradient based features over densely sampled sliding windows~\cite{felzenszwalb2010object}.Such methods achieve good results on classes like human and vehicles, but they are very inefficient since they evaluate thousands of windows in an image, and false positve detections arise. To reduce the number of windows evaluated,  recently category independent object proposals~\cite{carreira2012cpmc,van2011segmentation,arbelaez2014multiscale} have been proposed to generate a small number of high quality regions or windows that are likely to be objects. These approaches dramatically reduce the number of candidates and reduce false positive detections. Using these object proposals~\cite{girshick14CVPR, BharathECCV2014} train and apply deep neural network models on large datasets to learn the feature extractor and classifiers, and achieve state-of-the-art performance on the Pascal VOC detection challenge. However, such category independent proposals do not adapt to different query classes and still lead to lots of unnecessary detector computation. 

{\bf Object Recognition using Context}. 
Context has been shown to improve object recognition and detection. In~\cite{gould2009decomposing, shotton2006textonboost, ladicky2010graph}, CRF models are used to combine unary potentials based on visual features extracted from superpixels with neighborhood constraints and low level context. Inter-object context in the scene has also been shown to improve recognition~\cite{galleguillos2010context, chen2011piecing}.~\cite{mottaghi2014role} shows that using contextual information can improve object detection using CRF models. However these approaches need to evaluate the high order co-occurrence statistics with \emph{all} other object classes appearing in the scene altogether, some of which may not be informative. Our framework, in contrast, only needs to evaluate the most related context in an active sequence before classifications of all objects are made, and goes beyond simple co-occurence statistics.~\cite{bogdan2012context} applied a sequential decision making framework to window selection by voting for the next window. However, the voting process needs to look up nearest neighbors in hundreds of thousands of exemplar window pairs in the training set because their context is purely based on appearance similarity at instance level, which is highly inefficient. By contrast, our model is based on context between semantic classes so we do not compute nearest neighbors over hundreds of thousands of windows in a high dimensional descriptor space to retrieve the voters, which greatly reduces computational complexity.
% We only need votes from a few regions within the search space of context class. Our context model achieves good accuracy while greatly reducing computational complexity.
